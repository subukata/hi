%
%  $Description: Author guidelines and sample document in LaTeX 2.09$
%
%  $Author: ienne $
%  $Date: 1995/09/15 15:20:59 $
%  $Revision: 1.4 $
%  $Revised: 1997/02/25  by Lluis Godo for FUZZ-IEEE'97 Proceedings

%-------------------------------------------------------------------------
% if you are using A4 paper, take the style file fuzzieee-a4.sty
%-------------------------------------------------------------------------
%\documentstyle[times,art10,twocolumn,fuzzieee-a4]{article}
%\documentstyle[10pt,twocolumn,fuzzieee-a4]{article}
%\documentstyle[twocolumn,fuzzieee-a4]{article}
 \documentstyle[twocolumn,fuzziea4,epsbox,esci9]{article}
%-------------------------------------------------------------------------
%\blm{*}ÇÃíËã`      added by T.Miyoshi 97/03/05
\newcommand{\blm}[1]{\mbox{\boldmath $#1$}}
\newcommand{\bmath}[1]{\mbox{\boldmath$#1$}}
%-------------------------------------------------------------------------
% if you are using 8.5 x 11 inch paper, take the style file fuzzieee-usa.sty
%-------------------------------------------------------------------------
%\documentstyle[times,art10,twocolumn,fuzzieee-usa]{article}
%\documentstyle[10pt,twocolumn,fuzzieee-usa]{article}
%\documentstyle[twocolumn,fuzzieee-usa]{article}
%-------------------------------------------------------------------------


%-------------------------------------------------------------------------
% take the % away on next line to produce the final camera-ready version
\pagestyle{empty}

%-------------------------------------------------------------------------
\begin{document}

\title{Algebraic Reconstruction Technique for Neurofuzzy Geotomography}

\author{ {\large Tetsuya Miyoshi, Hajime Tabuchi and Hidetomo Ichihashi} \\
{\normalsize  Department of Industrial Engineering}\\
{\normalsize  Osaka Prefecture University} \\
{\normalsize  1-1 Gakuen-cho, Sakai, Osaka 593, JAPAN}\\
{\normalsize  {\tt miyoshi@ie.osakafu-u.ac.jp}}\\
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
%\and
%{\large Hajime Tabuchi}\\
}

\maketitle
\thispagestyle{empty}

\begin{abstract}
A new Algebraic Reconstruction Techniques(ART) are  developed for a neurofuzzy
geotomography to accelerate the convergence of learning phase and  to reduce
the learning time or iteration times.
The  learning algorithm is derived from a constrained optimization problem.
Minkowski norm of the corrections of parameters  is used as the objective function of the optimization problem.
Some computer simulation results show that   smooth distributions of a material parameter are  obtained by  using the  Minkowski norm.
Furthermore, the proposed method is applied to the experimental data collected at a dam site by cross borehole seismic probing.
\end{abstract}


%Algebraic Reconstruction Techniques(ART) were developed to  reconstruct
%the material  parameter from measured  propagation data, in which
%corrects of the estimated material parameter are repeated to bring each
% projection of the estimate into agreement  with the corresponding measured
%  projections.
%In this paper we propose a learning algorithm based on the ART to accelerate
% the convergence of learning phase and apply it to a neurofuzzy geotomography
% to reduce the learning time or iteration times.



%-------------------------------------------------------------------------
\Section{Introduction}


Computerized Tomography(CT) is one of the methods to visualize a spatial distribution of material parameters, such as attenuation rate or propagation velocity, from measured projection data.
Geotomography(Geophysical Tomography) has been used in geological and mineral prospecting applications and can image geological structures using some iterative techniques.
Algebraic Reconstruction Techniques(ART) were introduced by Gordon {\it et al.}\cite{gordon} for solving the problem of three dimensional reconstruction from projections in electron microscopy and radiology.
Variations on the ART\cite{gordon2,herman1,herman2,sweeney} have been proposed and all ART algorithms  share a property of iteratively attempting to match the weighted or unweighted sums of appropriate reconstruction elements with the corresponding projection data.
Dines and Lytle proposed the iterative method for geophysical tomography by using the ART and analyzed synthetic and experimental data \cite{dines}.



The ART and the normalized least mean square (NLMS) are the similar algorithms
of  iterative learning.
The NLMS  also is a  method to accelerate the convergence of the learning phase\cite{brown}.
It is only the learning rate that distinguishes the LMS and the NLMS learning rules.
In the LMS rule, the learning rate is chosen by trial and error, whereas in the NLMS rule, the learning rate is determined adaptively such that the square output error is minimized.
The NLMS adaptation rule is self-normalizing.



In this paper we propose a learning algorithm of neurofuzzy geotomography based on the ART and NLMS to accelerate the convergence of learning phase.
The learning algorithm has the property of iteratively attempting to match
the line integral of the fuzzy model with the corresponding projection data.
A constrained optimization problem, in which squared error between the line integral of the fuzzy model and corresponding projection data is used as an objective function, is solved to obtain  corrections for  elements of unknown parameter vector.
We generalize the learning algorithm by
introducing the  Minkowski norm (the sum of $s$-th power of the correction) to the objective function   in stead of Euclidean norm (squared errors).
In consequence of using the  Minkowski norm more smooth distribution of a material parameter is obtained.
We show some reconstruction results from the artificially  generated  data
and collected field data.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Section{Neurofuzzy Geotomography}

In this section we review  a neurofuzzy approach to computerized tomography\cite{tabuchi}.
Let $A_{ik}$ denote the membership function of the $k$-th fuzzy rule in the domain of the $i$-th input variable $x_i$. The $k$-th rule is written as
``If $x_1$ is $A_{1k}$ and $x_2$ is $A_{2k}$, then $y$ is $w_k$."  The conclusion part of the fuzzy reasoning rule that infers the output $y$ is simplified as real number $w_k$. In the case of Gaussian membership function, $A_{ik}$ is defined as
%
\begin{equation}
  A_{ik}(x_i) = \exp { \left( - \frac{(x_i - a_{ik})^2}{b_{ik}}
                        \right) }
\end{equation}
%
where the parameters $a_{ik}$  and $b_{ik} (i=1,...,N)$ are given for each $k$ and are changed in the training procedure. The final output $y$ is written as
%
\begin{equation}
  y = f(x_1,x_2) = \sum_{k=1}^K \mu_k (x_1,x_2) \cdot w_k
  \label{eq:model}
\end{equation}
%
where $\mu_k (x_1,x_2)$  is the compatibility degree of the premise part of the $k$-th fuzzy rule, which is defined as
the product of membership function $A_{ik}$
%
\begin{equation}
  \mu_k (x_1,x_2) = A_{1k}(x_1) \times A_{2k}(x_2)
\end{equation}
%
In Fig.\ref{probing} the line from A (0,$x_2^L$) to B (1,$x_2^R$) can be written as $ x_2 = \alpha x_1 + x_2^L $  where $ \alpha = x_2^R - x_2^L$.
Let $(x_1,x_2)$  be the coordinate of a point on the line AB. Then
the line integral of $f(x_1,x_2)$ along the path $AB$ can be written as
%
\begin{equation}
  \int_{ - \infty}^{ \infty} f(z)dz =
                   \sum_{k=1}^K \zeta_k \sqrt{ \pi b_k} \cdot w_k
  \label{integral}
\end{equation}
%
where
%
\begin{equation}
  \zeta _k = \exp { \left(
                        -
                        \frac
                          {(\alpha a_{1k} + x_2^L - a_{2k})^2 }
                          {(1+ \alpha ^2) b_k}
                              \right)}
\end{equation}




%
%%%%%%%%%%%%%%%%%%
%%%  CT3:figure01
\begin{figure}[t]
	\begin{center}
		\epsfile{file=./eps_fig/fig01.eps,height=30mm}
	\end{center}
  \caption[A region of probing.]{A region of probing.}
  \label{probing}
\end{figure}
%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%
%---fig02.tex----%
\begin{figure}
	\begin{center}
		\epsfile{file=./eps_fig/fig02.eps,height=30mm}
	\end{center}
  \caption[Propagation paths]{Propagation paths.}
    \label{propagation}
\end{figure}
%%%%%%%%%%%%%%%%%%
%
 We here consider an application of neurofuzzy modeling to the geotomography.
In Fig.\ref{propagation}, a typical situation, the data collection system scans the rectangular region ($CDEF$) with some signal sources located in two boreholes $CD$ and $CF$ and some receivers in the opposite $EF$ and $DE$.
In Fig.\ref{propagation}  typical ray paths ($AB$ and $A^{\prime}B^{\prime}$) are indicated for signal propagations.
Let the line segment $AB$ and $A^{\prime}B^{\prime}$ be propagation paths $L_p$ and $L^{\prime}_p$ respectively, and $P$ be the number of propagation paths.
We express the distribution of some material parameter such as attenuation rate by the fuzzy model $f(x_1,x_2)$ in Eq.(\ref{eq:model}), where $(x_1,x_2)$ is the coordinate in the region.
Assuming the straight line ray-optic model, the projection along a path $L_p$ can be written as
\begin{equation}
  I_p = \int_{L_p} f(x_1,x_2) dz , \hspace{10mm} (p=1,2,\cdots,P)
\end{equation}
%
Synthetic propagation data $I_p^*$  can be measured  along  propagation paths.
In a similar manner, the projections $I_p^{'*}$ along a path $L^{\prime}_p$ can be measured.



Let a cost function for the evaluation of the approximation be
\begin{equation}
E_1 = \frac{1}{2} \left\{ \sum_{p=1}^P (I_p - I_p^*)^2 + \sum_{p=1}^{P^{\prime}}          (I^{\prime}_{p} - I^{\prime*}_{p})^2 \right\}
\end{equation}
and formulate a nonlinear mathematical programming problem to find the values of parameters $a_{ik}$ , $b_{k}$  and $w_k$ in the neurofuzzy model,  that minimize the cost function.
If Gaussian functions are allocated inside the region, the value of Gaussian function $\mu _k (x_1,x_2)$ is almost $0$ on the both boundaries of the region, then the line integral of the fuzzy model is approximated by
Eq.(\ref{integral}).
And in the case that Gaussian functions are allocated on the boundary of the region, since $\mu _k (x_1,x_2)$ is almost $0$ on the opposite side of the region, the line integral is half of Eq.(\ref{integral}) approximately.
The line integral $I_p$ of $f(x_1,x_2)$ along the path $L_p$ can be approximated as
%
\begin{equation}
I_p = \sum_{k=1}^K \zeta_{kp} \sqrt{ \pi b_k} w_k +
             \frac{1}{2}
             \sum_{k=K+1}^{K+J} \zeta_{kp} \sqrt{ \pi b_k} w_k
\end{equation}
%
where $K$ and $J$ are the numbers of Gaussian functions that are allocated inside the region and on the boundaries of the region  respectively.

It is hard to reconstruct detailed pictures of the spatial distribution from very small number of projection data.
It is clearly an ill-posed problem because the information in the data is not sufficient to reconstruct the distribution in the region uniquely.
Techniques that exploit smoothness constrains in order to transform an ill-posed problem into a well-posed one are well known under the term of reguralization theory \cite{poggio,suzuki}.
Let a cost function for the regularization  be as
%
\begin{eqnarray}
E_2 &=& \frac{1}{2} \sum_{(x_1,x_2) \in W}
         \left\{\left( \frac{\partial^2 f(x_1,x_2)}{\partial x_1^{\ 2}}
                \right)^2 \right. \nonumber \\
    & &	\hspace{15mm}
             +  \left.\left( \frac{\partial^2 f(x_1,x_2)}{\partial x_2^{\ 2}}
                \right)^2
         \right\}
\end{eqnarray}
%
where $W$ is the set of data points chosen uniformly in the region.
Let a total cost function be $E = E_1 + \eta E_2 $, where $\eta$ is positive weighting constant for regularization conditions,
and formulate a nonlinear mathematical programming problem to find the values of parameters $a_{ik}$ , $b_{k}$  and $w_k$ in the fuzzy model, which minimize the total cost function.
The learning rules of $a_{ik}$ , $b_{k}$  and $w_k$ are based on the steepest descent method(SDM).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%   ART   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Section{ Instantaneous Learning Algorithm Based on ART  with Minkowski Norm}

Generally speaking,  it is an important and difficult problem to determine the appropriate learning rate.
Usually  learning rates in such learning algorithms that use  gradient descent methods  are chosen mainly by trial and error.
However, there are two problems with the  approach.
If the learning rate is not small enough, the total sums of square errors can diverge to high values instead of decreasing.
A very conservative estimate on the other hand will unnecessarily slow down the learning process.
Algebraic Reconstruction Techniques(ART) algorithms  used in geotomography have a simple procedure with repeated corrections to bring each projection of the estimate into agreement with the corresponding measured projection.
We propose a learning algorithm in which  the learning rate changes
 adaptively   using the concept of the ART.




Let a line integral of the fuzzy model along a propagation path  be
 a function  $y(\blm{w})$  of vector $\blm{w}$ which consists of unknown parameter $a_{ik}$, $b_k$, $w_k$, $i=1,2$, $k=1 \cdots K$.
When $\Delta \blm{w}$ is a very small change of $\blm{w}$, $y(\blm{w})$ can be developed into a Taylor series with respect to $\blm{w}$  as
%
\begin{equation}
  y(\blm{w} + \Delta \blm{w}) = y(\blm{w}) + \nabla y(\blm{w})^T \Delta \blm{w}
\end{equation}
%
The symbol $\nabla$ indicates the differential operator $\partial y/\partial w_r$.
To derive a learning algorithm based on the concept of  the ART, let us consider the  constrained optimization problem as
%
\begin{eqnarray}
	&&min.
		\hspace{10mm} \sum_{r=1}^R (\Delta w_r)^{s}	\label{eq:min} \\
	&&s.t.
		\hspace{10mm} \sum_{r=1}^R \left|\frac{\partial y}
    		                                 {\partial w_r}
        		                  \right| \Delta w_r = |\delta|
		\label{eq:joken1}
\end{eqnarray}
%
\begin{equation}
	\hspace{20mm} \Delta w_rÅÜ0
	\label{eq:joken2}
\end{equation}
%
where, $\Delta w_r$ is the correction for $r$-th element of unknown parameter vector $\blm{w}$, $R$ is the total number of unknown parameters and $\delta$ is the difference between the measured value $I_p^*$ and estimated value $y(\blm{w})$, that is, $\delta = y(\blm{w})-I_p^*$ÅD
Note that $s$ is a positive real number,
 then  a constraint Eq.(\ref{eq:joken2}) is  added as  the non-negativity restrictions.
The constrained optimization problem represented by Eqs.(\ref{eq:min})--(\ref{eq:joken2}) is geometrically illustrated in Fig.\ref{chev}, where  the 2-dimensional parameter space is shown.
In Fig.\ref{chev} the solid line representes  a hyperplane ($y(\blm{w})=I_p^*$) on which  the constraint represented by Eq.(\ref{eq:joken1}) is satisfied.
Let $\blm{w}_n$ be  a parameter vector after $n$  learning iterations.
A correction vector $\Delta \blm{w}$ is chosen such that a parameter vector $\blm{w}_{n+1}$ after a correction  can satisfy the constraint represented by Eq.(\ref{eq:joken1}), that is, the parameter vector $\blm{w}_{n+1}$  must be on the hyperplane.
The object of the constrained optimization problem is to minimize the sum of $s$-th power of corrections(Minkowski norm of corrections).
When $s=2.0$, a solution of the optimization problem equals the correction by  the ART algorithm.
 Since the Euclidean distance of $\Delta \blm{w}$ is minimized in case of $s=2.0$, $\Delta \blm{w}$ is orthognal to  the hyperplane.
 The parameter vector after a correction is denoted as $\blm{w}_{n+1}^{'}$ in Fig.\ref{chev}.
When $s$ approaches infinity, Eq.(\ref{eq:min}) is referred to as the minimax norm and  the parameter vector after a correction is  $\blm{w}_{n+1}^{''}$ in Fig.\ref{chev}.
As $s$ becomes large, all elements of correction vector $\Delta \blm{w}$
take almost same values.


%%%%%%%%%%%%%%%%%%
\begin{figure}[tb]
	\begin{center}
		\epsfile{file=./eps_fig/fig03.eps,height=50mm}
	\end{center}
  \caption[$w$,$\Delta w$ and hyperplane $y=I_{p}^{*}$ in the parameter space.]
	{$w$,$\Delta w$ and hyperplane $y=I_{p}^{*}$ in the parameter space.}
	\label{chev}
\end{figure}
%%%%%%%%%%%%%%%%%%

We define the  Lagrangian function as
%
\begin{eqnarray}
L &=& \sum_{r=1}^R (\Delta w_r)^{s}
   + \lambda_0 (|\delta| -\sum_{r=1}^R \left|\frac{\partial y}{\partial w_r}\right| \Delta w_r) \nonumber \\
	& & \hspace{15mm} - \sum_{r=1}^R \lambda_{1r} \Delta w_r
\end{eqnarray}
%
where, $\lambda_0,\lambda_{1r}$ are Lagrangian multipliers.
If $\Delta w_r$ is the local optimal solution,  $L$, $\lambda_0$ and $\lambda_{1r}$  satisfy the following Kuhn-Tucker conditions
%
\begin{eqnarray}
\frac{\partial{L}}
     {\partial{\Delta w_r}} &=&
				                       s(\Delta w_r)^{s-1}
				                   			- \lambda_0 \left|\frac{\partial y}
				                                            {\partial w_r}
				                                 \right|
				                     - \lambda_{1r} = 0
				\label{ragu1} \\
		\lambda_{1r} \Delta w_r &=& 0
				\label{ragu2}
\end{eqnarray}
%
\begin{equation}
		\Delta w_r ÅÜ0, \hspace{5mm} \lambda_0ÅÜ0, \hspace{5mm} \lambda_{1r}ÅÜ0
				\label{ragu3}
\end{equation}
%
and
\begin{eqnarray}
\frac{\partial{L}}{\partial{\lambda_0}} &=&
				|\delta| - \sum_{r=1}^R \left|\frac{\partial y}{\partial w_r}\right|
				\Delta w_r = 0
				\label{ragu4}
\end{eqnarray}
%
for $\;r=1,\cdots,R$. Eqs.(\ref{ragu1})Å`(\ref{ragu3}) lead to the solution
%
\begin{eqnarray}
	\Delta w_r = \left(\frac{\lambda_0}{s}
	             \right)^\frac{1}{s-1}
	             \left|\frac{\partial y}
	                        {\partial w_r}
	             \right|^\frac{1}{s-1}
	\label{del}
\end{eqnarray}
%
Combining Eq.(\ref{del}) with Eq.(\ref{ragu4}) gives
%
\begin{equation}
		|\delta| = \left(\frac{\lambda_0}{s}
		           \right)^\frac{1}{s-1} \sum_{r=1}^R
		           \left|\frac{\partial y}
		                      {\partial w_r}
		           \right|^\frac{s}{s-1}
\end{equation}
%
and we have
%
\begin{equation}
		\Delta w_r = \frac{|\delta|}{\Sigma}
		             \left|\frac{\partial y}{\partial w_r}
		             \right|^\frac{1}{s-1}
		\label{kousin}
\end{equation}
%
where
%
\begin{equation}
		\Sigma = \sum_{r=1}^R \left|\frac{\partial y}{\partial w_r}
		                      \right|^\frac{s}{s-1}
\end{equation}
%
The solution $\Delta w_r$ denotes absolute value of corrections,
then we set the sign taking steepest descent direction  into account  as $-sgn(\delta \partial y /\partial w_r )$.
The learning algorithm is given by
%
\begin{equation}
w_r^{NEW} = w_r^{OLD} - \tau sgn \left(\delta \frac{\partial y}{\partial w_r} \right) \Delta w_r
\end{equation}
%
where, $\tau$ is a relaxation rate.

To demonstrate the effectiveness of Minkowski norm based on the ART, we carry
 out a numerical simulation.
We generate a set of input output pair of data from a function denoted by dashed line in Fig.\ref{ART}.
 ``$\bullet $'' represents the training data .
 The number of training data is 15 and each training data contains noise.
The function is identified using the fuzzy model which consists of the 15 fuzzy rules.
We set initial values of the parameters $w_k$ , $b_k$ to 0.0 and 0.01 respectively. $a_k$ is uniformly spaced in unit interval[0,1].
Fig.\ref{ART} shows the output of the fuzzy model (a) in case of $s=2.0$
 (the original ART)  and (b) in case of $s=10.0$.
(a) and (b) show the results after 150 iterations and 1000 iterations respectively.
The outputs of fuzzy models are drawn by the solid curves.
Comparing Fig.\ref{ART}(b) with (a), the output of the model obtained  by the proposed method is more smooth at the early stage of learning iteration.

%%%%%%%%%%%%%%%%%%
\begin{figure}[tb]
	\begin{center}
		\epsfile{file=./eps_fig/fig04.eps,height=65mm}
	\end{center}
  \caption[Effect of ART with Generalized Chebyshev Norm]{Effect of ART with  Minchowski Norm}
  \label{ART}
\end{figure}
%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% simulation result  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\Section{Computer Simulations}

The performance of the reconstruction algorithm based on the ART is demonstrated using computer generated data.
Fig.\ref{compare}(a) shows an artificially generated test distribution of material parameters such as attenuation rate or propagation velocity,
which is drawn with 3-D graphics and contour curves.
We locate four transmitters on a borehole $CD$ and $CF$, and the  four receivers on  $DE$ and $EF$ respectively.
We set 30  projection paths  as shown in Fig.\ref{propagation}.
We used 16 fuzzy rules.

%%%%%%%%%%%%%%%%%%
\begin{figure}[tb]
	\begin{center}
		\epsfile{file=./eps_fig/fig05.eps,height=40mm}
	\end{center}
  \caption[The value curves of cost function]
    				{The value curves of cost function.}
  \label{gosa}
\end{figure}
%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%

\begin{figure}[tb]
		\begin{center}
			\epsfile{file=./eps_fig/fig06a.eps,height=25mm}

			(a) the simulated test distribution
			\epsfile{file=./eps_fig/fig06b.eps,height=25mm}

			(b) reconstruction by the  ART
			\epsfile{file=./eps_fig/fig06c.eps,height=25mm}

			(c) reconstruction by the SDM
		\end{center}
		\caption[Results of the reconstruction]
      			{Results of the reconstruction. \\
      			   The number of propagation paths is 30.
      			   16 Gaussian functions are used.
      			   (a)the simulated test distribution of a material parameter,
      			   (b)the output of $f(x_{1},x_{2})$ using learning algorithm
      			    based on ART,
      			   and (c)the output of $f(x_{1},x_{2})$ using steepest descent method.
      			   }
		\label{compare}
\end{figure}

%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%

\begin{figure}[tb]
		\begin{center}
			\epsfile{file=./eps_fig/fig07a.eps,height=25mm}

			(a)$s=3.0$ \\
			\epsfile{file=./eps_fig/fig07b.eps,height=25mm}

			(b)$s=4.0$ \\
			\epsfile{file=./eps_fig/fig07c.eps,height=25mm}

			(c)$s=6.0$ \\
		\end{center}
		\caption[Results of the reconstruction with various values $s$]
      			{Results of the reconstruction with various values $s$,
      			 (a)$s=3.0$, (b)$s=4.0$ and (c)$s=6.0$.
      			 16 Gaussian functions are used. }
		\label{s}
\end{figure}

%%%%%%%%%%%%%%%%%%%

The proposed learning algorithm based on the ART is compared with the conventional  learning algorithm SDM.
In Fig.\ref{gosa}  the value curves of the square sum of  errors are plotted versus iteration number. The errors between the collected data and the output of the fuzzy model decrease more rapidly in the case of proposed ART than the SDM.
We set  $\tau=0.1$ and $s=2.0$ for the proposed algorithm and the learning rate to 0.001 for the SDM.
The errors decreased to 0.019 and 0.107 at 1,000 iterations.
Even after 10,000 iterations the error 0.031 remained by the SDM.



The reconstruction images are represented by both 3-D graphics and contour
 curves, and ``$\circ$'' represents a center of Gaussian function after
 learning.
Gaussian functions were initially allocated uniformly inside the region and on the boundaries of the
 region.
 The reconstructed images by both  learning algorithms are shown in
 Fig.\ref{compare} where (a) the test distribution, (b) the result with the
 learning algorithm based on the ART at 10,000 iteration and (c) the result  with the conventional learning algorithm at 100,000 iterations are shown respectively.
Comparing (b) with (c) we cannot find much difference between them.


Next, we discuss the value of $s$ in Eq.(\ref{eq:min}).
In the reconstruction procedure we used the same training data generated from the test distributionÅ@ shown in Fig.\ref{compare}(a).
Three values of $s$ were chosen.
Figs.\ref{s} (a), (b) and (c) show the reconstruction images by the algorithms based on the ART with the parameters $s$ being set to 3.0, 4.0 and 6.0 respectively.
The squared error was smallest when $s=3.0$.
As shown in Fig.\ref{s}, the output of the model(b) obtained in case of $s=4.0$ is more smooth than (a).



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% field data         %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Section{Application to Field Data}

The proposed algorithm was applied to the field data collected by cross-borehole seismic probing at a dam site in Mie Prefecture, Japan.
A site plan with all observed ray paths is shown in Fig.\ref{r_region}.
Our aim is to determine whether the proposed method would be useful in detecting changes in a natural geologic structure.
There are three vertical boreholes in Fig.\ref{r_region}.
The transmitters and receivers were spaced at 2.5m and 0.5m intervals respectively in each boreholes.
In Fig.\ref{r_region} the transmitters and receivers are indicated by
``$\bullet$ '' and ``$\circ $'' respectively.
The numbers of propagation paths were 269(No.1-No.2) and 240(No.2-No.3).
Seismic waves were generated in the all boreholes and were measured in the all boreholes.
As the received signals carry time of flight information for velocity measurements, measurements of the travel-time of seismic waves were employed to make an image of cross section.
The travel-time is a line-integral of an inverse of velocity along each path, which is called as ``slowness''.
The distribution of slowness is obtained in case of using the travel-time as the training data.

%%%%%%%%%%%%%%%%%%%

\begin{figure}[tb]
	\begin{center}
		\epsfile{file=./eps_fig/fig09.eps,height=55mm}
	\end{center}
	\caption[Cross-borehole sampling at a dam site using multiple locations
	         for the transmitter and receiver probes]
	        {Cross-borehole sampling at a dam site using multiple locations
	         for the transmitter and receiver probes}
	\label{r_region}
\end{figure}
%%%%%%%%%%%%%%%%%%%

We attempted to reconstruct the distribution of slowness from
collected data of travel-time along  the paths by the proposed algorithm.
After that, we calculated the distribution of velocity which is the inverse of slowness.
Fig.\ref{fig:r_ct} shows the obtained distributions of the velocity represented
with 3D-graphics and  contour curves. The velocity contour interval is
1km/sec.  The iteration number is set to 10,000.
 In Fig.\ref{fig:r_ct}, the two different results in which  $s$ are set to  3.0 and 4.0 are illustrated.
The results with $s=3.0$ are shown in Fig.\ref{fig:r_ct}(a).
The results with $s=4.0$ are shown in Fig.\ref{fig:r_ct}(b).
As shown in Figs.\ref{fig:r_ct}(a) and (b), the output of the fuzzy model obtained with $s=4.0$ is more smooth than with $s=3.0$.
The velocity distribution obtained by the proposed learning algorithm agrees with the knowledge of  geological experts.

%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure*}[tb]
		%\hspace{10mm}
		\begin{center}
		  \epsfile{file=./eps_fig/fig10a_l.eps,height=30mm}
		  \hspace{15mm}
		  \epsfile{file=./eps_fig/fig10a_r.eps,height=30mm}

		  (a) $s=3.0$
		\end{center}

		%\hspace{10mm}
		\begin{center}
		  \epsfile{file=./eps_fig/fig10b_l.eps,height=30mm}
		  \hspace{15mm}
		  \epsfile{file=./eps_fig/fig10b_r.eps,height=30mm}

		  (b) $s=4.0$
		\end{center}
	\caption[Image of cross section obtained by the proposed Geotomography]
		      {Image of cross section obtained by the proposed Geotomography.
		       The velocity profile is shown. Spot values are given in km/sec.
		       The velocity contour interval is 1km/sec.}
	\label{fig:r_ct}
\end{figure*}

%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% conclusion         %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Section{Conclusion}

In this paper we have proposed a novel learning algorithm for the neurofuzzy geotomography based on the ART to accelerate the convergence of learning.
A constrained optimization problem with the Minkowski norm is formulated
and a learning algorithm using its solution  is derived.
It is demonstrated through some numerical simulations that
smooth distribution of material parameters is obtained by the proposed algorithm.
Furthermore, we applied the proposed algorithm to the field data and reconstructed the distribution of velocity of seismic wave at a dam site.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% citation  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{thebibliography}{9}


 \bibitem{brown}
    M.Brown and C.Harris,
    ``Neurofuzzy Adaptive Modelling and Control'',
    Prentice Hall, New York, 1994.

 \bibitem{Broomhead}
     D.S.Broomhead and D.Lowe,
     ``Multivariable Functional Interpolation and Adaptive Networks,
     Complex Systems'',
     Vol.2, pp.321-355, 1988.

 \bibitem{dines}
    K.A.Dines and R.J.Lytle,
    ``Computerized Geophysical Tomography'',
    Proc. of IEEE, Vol.67, No.7, pp.1065-1073, 1979.

  \bibitem{gordon}
  R.Gordon, R.Bender and G.T.Herman,
  ``Algebraic Reconstruction Techniques(ART) for Three-dimensional
  Electron Microscopy and X-ray Photography'',
  J. Theor. Biol. No.29, pp.471--481, 1970.

  \bibitem{gordon2}
    R.Gordon,
    ``A Tutorial on ART'',
    IEEE Trans. on Nuclear Science, Vol.NS--21, pp.78--93, 1974.

  \bibitem{herman1}
    G.T.Herman,
    ``Reconstruction of Binary Patterns from a Few Projection'',
    Interna. Computing Symposium  1973, ed.A.Guenther {\it et al.},
    North Holland Publ. Co., pp.371--379,1974.

  \bibitem{herman2}
    G.T.Herman, A.Lent and S.Rowland,
    ``ART : Mathematics and Applications. A Report on the Mathematical
    Foundations and on the Applicability to Real Data of the Algebraic
    Reconstruction Techniques '', J. Theor. Biol. Vol.42, pp.1--32,1973.


  \bibitem{poggio}
    T.Poggio and F.Girosi,
    ``Regularization Algorithms for Learning that Are Equivalent to
    Multilayer Networks '',
    Sciences, Vol.247, pp.978-982, 1990.

 \bibitem{rumelhart}
   D.E.Rumelhart, J.L.McClelland and the PDP Research Group,
   ``Parallel Distributed Processing'',
   Cambridge, MA: MIT Press, 1987.

 \bibitem{suzuki}
    M.Suzuki, K.Judd, K.Aihara and M.Kotani,
    ``Approximation of the Logistic Mapping with Radial Basis Function
     Networks'',
     Transactions of IEICE, Vol.J76-A, No.8, pp.1177-1184, 1993.

 \bibitem{sweeney}
    D.W.Sweeney and T.M.Vest,
    ``Reconstruction of Three-dimensional refractive Index Fields from
     Multidirectional Interferometic Data'',
    Applied Optics, Vol.12, No.11, pp.1649--2664,1973.

  \bibitem{tabuchi}
    H.Tabuchi, T.Miyoshi, H.Ichihashi and K.Ohno,
    ``Computerized Tomography with Radial Basis Functions Network'',
    Proc. of ICNN'95, pp.2258-2263, 1995.

\end{thebibliography}

\end{document}






